# ANB Rising Stars Showcase

## Informaci√≥n del Equipo

**Grupo 11 - Team ANB**
- Sergio Fernando Barrera Molano - [sf.barreram1@uniandes.edu.co] - [Rol en el proyecto]
- Harold Andr√©s Bartolo Moscoso - [h.bartolo@uniandes.edu.co] - [Rol en el proyecto]
- Edwin Hern√°n Hurtado Cruz - [eh.hurtado@uniandes.edu.co] - [Rol en el proyecto]
- Juan Jos√© Restrepo Bonilla - [jj.restrepob1@uniandes.edu.co] - [Rol en el proyecto]

*Por favor, actualice esta secci√≥n con la informaci√≥n real del equipo antes de la entrega.*

## Video de Sustentaci√≥n

El video de sustentaci√≥n para la Entrega 1 estar√° disponible en: [sustentacion/Entrega_1/](sustentacion/Entrega_1/)

## Enlaces Importantes

- **Documentaci√≥n Completa**: [docs/Entrega_1/README.md](docs/Entrega_1/README.md)
- **Plan de An√°lisis de Capacidad**: [capacity-planning/CAPACITY_ANALYSIS_PLAN_B.md](capacity-planning/CAPACITY_ANALYSIS_PLAN_B.md)
- **Colecciones Postman**: [collections/](collections/)
- **API Documentation**: http://localhost:8000/docs (cuando la aplicaci√≥n est√© ejecut√°ndose)
- **Video de Sustentaci√≥n**: [sustentacion/Entrega_1/](sustentacion/Entrega_1/)
- **Pipeline CI/CD**: [GitHub Actions](https://github.com/your-repo/actions) (ver secci√≥n CI/CD m√°s abajo)

## Descripci√≥n del Proyecto

Plataforma web escalable para la gesti√≥n del programa Rising Stars Showcase de la Asociaci√≥n Nacional de Baloncesto (ANB), que permite a j√≥venes jugadores subir videos de sus habilidades para ser evaluados y votados por el p√∫blico y jurado especializado.

## Tecnolog√≠as Utilizadas

- **Backend**: Python 3.13 + FastAPI 0.118
- **Base de Datos**: PostgreSQL
- **Procesamiento As√≠ncrono**: Celery + Redis
- **Proxy Reverso**: Nginx
- **Servidor WSGI**: Uvicorn
- **Contenedores**: Docker + Docker Compose
- **OS Base**: Ubuntu Server 24.04 LTS

## Arquitectura del Sistema

El sistema est√° compuesto por los siguientes componentes:
- API REST (FastAPI)
- Workers de procesamiento as√≠ncrono (Celery)
- Broker de mensajes (Redis)
- Base de datos (PostgreSQL)
- Proxy reverso (Nginx)
- Almacenamiento de archivos (sistema de archivos local)

## Instalaci√≥n y Despliegue

### Prerrequisitos
- Docker y Docker Compose
- Python 3.13+ (para desarrollo local)
- Ubuntu Server 24.04 LTS (recomendado)

### Despliegue con Docker
```bash
# Clonar el repositorio
git clone <repository-url>
cd MISW4204-GRUPO11-ANB_Rising_Stars_Showcase

# Construir y ejecutar los servicios
docker-compose up --build -d

# La aplicaci√≥n estar√° disponible en:
# - API: http://localhost:8000
# - Nginx: http://localhost
# - Flower (Celery): http://localhost:5555
# - Swagger UI: http://localhost:8000/docs
```

### Comandos de Gesti√≥n

```bash
# Levantar todos los servicios
docker-compose up -d

# Ver logs de todos los servicios
docker-compose logs -f

# Ver logs de un servicio espec√≠fico
docker-compose logs -f api
docker-compose logs -f worker
docker-compose logs -f postgres

# Detener todos los servicios
docker-compose down

# Detener y eliminar vol√∫menes (limpieza completa)
docker-compose down -v --remove-orphans

# Reconstruir desde cero
docker-compose down -v --remove-orphans
docker system prune -a --volumes -f
docker-compose up --build -d
```

### Desarrollo Local
```bash
# Crear y activar entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Instalar dependencias
pip install -r requirements.txt

# Configurar variables de entorno
cp .env.example .env

# Ejecutar migraciones
alembic upgrade head

# Ejecutar la aplicaci√≥n
uvicorn app.main:app --reload
```

## API Documentation

La documentaci√≥n interactiva de la API est√° disponible en:
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

## Estructura del Proyecto

```
‚îú‚îÄ‚îÄ app/                    # C√≥digo fuente de la aplicaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ api/               # Endpoints de la API REST
‚îÇ   ‚îú‚îÄ‚îÄ core/              # Configuraci√≥n y utilidades
‚îÇ   ‚îú‚îÄ‚îÄ models/            # Modelos de base de datos
‚îÇ   ‚îú‚îÄ‚îÄ schemas/           # Schemas de Pydantic
‚îÇ   ‚îú‚îÄ‚îÄ services/          # L√≥gica de negocio
‚îÇ   ‚îî‚îÄ‚îÄ workers/           # Workers de Celery
‚îú‚îÄ‚îÄ docs/                  # Documentaci√≥n del proyecto
‚îÇ   ‚îî‚îÄ‚îÄ Entrega_1/        # Documentaci√≥n espec√≠fica de la entrega 1
‚îú‚îÄ‚îÄ collections/           # Colecciones de Postman
‚îú‚îÄ‚îÄ capacity-planning/     # An√°lisis de capacidad
‚îú‚îÄ‚îÄ tests/                 # Pruebas unitarias
‚îú‚îÄ‚îÄ nginx/                 # Configuraci√≥n de Nginx
‚îú‚îÄ‚îÄ docker-compose.yml     # Orquestaci√≥n de servicios
‚îî‚îÄ‚îÄ Dockerfile            # Imagen de la aplicaci√≥n
```

## Funcionalidades Principales

### Gesti√≥n de Usuarios
- Registro de jugadores
- Autenticaci√≥n con JWT
- Gesti√≥n de perfiles

### Gesti√≥n de Videos
- Carga de videos
- Procesamiento as√≠ncrono (recorte, formato, watermark)
- Consulta y eliminaci√≥n de videos propios

### Sistema de Votaci√≥n
- Votaci√≥n p√∫blica por videos
- Ranking din√°mico de jugadores
- Control anti-fraude (un voto por usuario por video)

## Pruebas

### Prerrequisitos para Ejecutar Pruebas
```bash
# Instalar dependencias de Python
pip install -r requirements.txt

# Instalar Newman CLI (opcional, para pruebas de API)
npm install -g newman
```

### Ejecutar Pruebas Unitarias
```bash
# Ejecutar todas las pruebas (32 tests)
python -m pytest tests/ -v

# Ejecutar con cobertura de c√≥digo
python -m pytest tests/ --cov=app --cov-report=term-missing

# Ejecutar pruebas espec√≠ficas
python -m pytest tests/test_auth.py -v
python -m pytest tests/test_videos.py -v
python -m pytest tests/test_public.py -v
```

**Resultado esperado:**
- ‚úÖ 32 tests pasando
- ‚úÖ 76% cobertura de c√≥digo
- ‚úÖ Sin errores cr√≠ticos

### Ejecutar Pruebas de API (Postman)
```bash
# Primero, ejecutar la aplicaci√≥n
docker-compose up

# En otra terminal, ejecutar las pruebas de Postman
newman run collections/anb-api.postman_collection.json \
  -e collections/postman_environment.json \
  --reporters cli
```

### Verificaci√≥n Completa del Sistema
```bash
# 1. Verificar que la aplicaci√≥n est√© ejecut√°ndose
curl http://localhost:8000/health

# 2. Ejecutar todas las pruebas unitarias
python -m pytest tests/ -v

# 3. Ejecutar pruebas de API (si la aplicaci√≥n est√° corriendo)
newman run collections/anb-api.postman_collection.json \
  -e collections/postman_environment.json
```

### Soluci√≥n de Problemas Comunes

**Error: "ModuleNotFoundError: No module named 'fastapi'"**
```bash
pip install -r requirements.txt
```

**Error: "could not translate host name 'postgres'"**
- Las pruebas unitarias usan SQLite autom√°ticamente
- Este error solo ocurre si se ejecuta la aplicaci√≥n sin Docker

**Error: "newman: command not found"**
```bash
npm install -g newman
```

**Error: "Connection refused" en pruebas de Postman**
- Aseg√∫rate de que la aplicaci√≥n est√© ejecut√°ndose: `docker-compose up`
- Verifica que el puerto 8000 est√© disponible

## CI/CD Pipeline

El proyecto incluye un pipeline de CI/CD con GitHub Actions que:
- Ejecuta pruebas unitarias
- Construye la aplicaci√≥n
- Ejecuta an√°lisis de calidad con SonarQube
- Valida la construcci√≥n de contenedores Docker

## An√°lisis de Capacidad (Plan B)

El proyecto incluye un an√°lisis completo de capacidad del worker implementado seg√∫n los requerimientos del documento de an√°lisis de capacidad.

### Ejecutar An√°lisis de Capacidad

#### üöÄ Demo R√°pido (Recomendado para empezar)
```bash
# Demo del Plan B - 2 minutos
python capacity-planning/run_plan_b_demo.py
```

**Resultado esperado:**
```
======================================================================
DEMO DEL PLAN B - AN√ÅLISIS DE CAPACIDAD DEL WORKER
======================================================================
Estado del demo: completed
Componentes probados: 3
Componentes exitosos: 3
Componentes fallidos: 0

==================================================
M√âTRICAS CLAVE
==================================================
Throughput del worker: 30.0 jobs/min
Trabajos procesados: 1
Throughput m√°ximo: 4.8 videos/min
Punto de saturaci√≥n: 500 trabajos
Estabilidad: Estable
Tasa de errores: 0.00%

==================================================
RECOMENDACIONES
==================================================
1. Throughput m√°ximo: 4.8 videos/min
2. Sistema estable en configuraci√≥n de prueba

======================================================================
DEMO COMPLETADO
======================================================================
```

#### üìä An√°lisis Completo
```bash
# An√°lisis completo del Plan B (10-15 minutos)
python capacity-planning/plan_b_executor.py

# Pruebas espec√≠ficas
python capacity-planning/worker_saturation_test.py --test-type saturation
python capacity-planning/worker_sustained_test.py --test-type sustained
```

#### üîß Prerequisitos
- **Redis**: Debe estar ejecut√°ndose (puerto 6379)
- **Python**: 3.11+ con dependencias instaladas
- **Tiempo**: Demo 2 min, An√°lisis completo 10-15 min

#### üìà Interpretaci√≥n de Resultados
- **Throughput**: Videos procesados por minuto
- **Saturaci√≥n**: Punto donde el sistema se degrada
- **Estabilidad**: Sistema estable bajo carga
- **Bottlenecks**: CPU, memoria, I/O identificados

#### üîß Troubleshooting

**Error: "Redis no conectado"**
```bash
# Iniciar Redis con Docker
docker run -d --name redis -p 6379:6379 redis:alpine

# O con Docker Compose
docker-compose up redis -d
```

**Error: "ModuleNotFoundError"**
```bash
# Instalar dependencias
pip install aiohttp psutil redis
```

**Demo no muestra resultados**
- Verificar que Redis est√© ejecut√°ndose
- Revisar logs para errores espec√≠ficos
- Ejecutar con `python -u` para output sin buffer

### Documentaci√≥n del An√°lisis de Capacidad

- **Plan de Pruebas**: [capacity-planning/CAPACITY_ANALYSIS_PLAN_B.md](capacity-planning/CAPACITY_ANALYSIS_PLAN_B.md)
- **Resultados de Pruebas**: [capacity-planning/RESULTS_SUMMARY.md](capacity-planning/RESULTS_SUMMARY.md)
- **Archivos de Resultados**: [capacity-planning/](capacity-planning/)
- **Scripts de Prueba**: 
  - `worker_bypass.py` - Bypass de la web para inyecci√≥n directa
  - `simulated_worker.py` - Worker simulado para procesamiento
  - `plan_b_executor.py` - Ejecutor completo del Plan B

### M√©tricas del Plan B

- **Throughput m√°ximo**: 45.8 videos/min (50MB, 4 workers)
- **Configuraci√≥n √≥ptima**: 50MB con 2 workers (32.1 videos/min)
- **Estabilidad**: Sistema estable con CPU < 90%, Memory < 85%
- **Bottlenecks identificados**: CPU, memoria e I/O

## CI/CD Pipeline

### Pipeline de GitHub Actions

El proyecto incluye un pipeline completo de CI/CD que se ejecuta autom√°ticamente en cada push y pull request:

#### Etapas del Pipeline

1. **Tests Unitarios** (`test`)
   - Ejecuta 32 tests unitarios
   - Genera reporte de cobertura (54%)
   - Sube resultados a Codecov
   - Excluye scripts de capacity-planning

2. **Build Autom√°tico** (`build`)
   - Construye imagen Docker
   - Valida Docker Compose
   - **Genera artefacto**: `docker-image.tar`
   - Retenci√≥n: 30 d√≠as

3. **An√°lisis de Calidad** (`sonarqube`)
   - SonarQube scan autom√°tico
   - Detecci√≥n de vulnerabilidades
   - M√©tricas de calidad del c√≥digo

4. **Security Check** (`security`)
   - Safety check para dependencias
   - Bandit security linter
   - Reportes de seguridad

#### C√≥mo Usar el Artefacto Generado

El pipeline genera autom√°ticamente un artefacto Docker que puedes descargar y usar:

```bash
# 1. Descargar artefacto desde GitHub Actions
# Ir a: Actions ‚Üí CI/CD Pipeline ‚Üí build job ‚Üí Artifacts
# Descargar: docker-image.tar

# 2. Cargar la imagen Docker
docker load -i anb-api.tar

# 3. Verificar que se carg√≥
docker images | grep anb-api

# 4. Ejecutar la aplicaci√≥n
docker run -d --name anb-api -p 8000:8000 anb-api:latest

# 5. Verificar que funciona
curl http://localhost:8000/health
```

#### Ubicaci√≥n del Artefacto

- **GitHub Actions**: `Actions` tab ‚Üí `CI/CD Pipeline` ‚Üí `build` job ‚Üí `Artifacts`
- **Nombre**: `docker-image`
- **Formato**: `anb-api.tar` (imagen Docker comprimida)
- **Retenci√≥n**: 30 d√≠as
- **Tama√±o**: ~100-500MB

#### Comandos Completos

```bash
# Descargar y usar el artefacto
wget https://github.com/your-repo/actions/runs/123456789/artifacts/docker-image.tar
docker load -i docker-image.tar
docker run -d --name anb-api -p 8000:8000 anb-api:latest
curl http://localhost:8000/health

# Ver logs
docker logs anb-api

# Detener
docker stop anb-api
docker rm anb-api
```

## Documentaci√≥n Adicional

- [Entrega 1 - Documentaci√≥n Completa](docs/Entrega_1/)
- [An√°lisis de Capacidad](capacity-planning/CAPACITY_ANALYSIS_PLAN_B.md)
- [Video de Sustentaci√≥n](sustentacion/Entrega_1/)

## Licencia

Este proyecto es desarrollado como parte del curso MISW4204 - Desarrollo de Software en la Nube, Universidad de los Andes.
